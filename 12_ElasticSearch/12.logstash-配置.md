# logstash-配置

- 创建脚本目录
    ```bash
    mkdir ./conf.d
    ```
    - 然后在里面创建conf文件来书写

- 书写脚本
    - 更改filter，加入grok做提取，加入geoip做处理
        ```json
        filter {
            //表示采用apache日志的方式来格式化，输出各种信息的json
            grok {
                match => { "message" => "%{COMBINEDAPACHELOG}"}
            }
            //表示对其中clientip字段所记录的ip地址进行进一步解释查询（包括经纬度，时区）
            geoip {
                source => "clientip"
            }
        }
        ```
    -  更改output到es，需要事先运行好es服务在9200端口
        ```json
        output {
            elasticsearch {
                hosts => [ "localhost:9200" ]
            }
            
            //可以换成写多个非主节点es的主机，会自动负载均衡
            elasticsearch {
                hosts => ["IP Address 1:port1", "IP Address 2:port2", "IP Address 3"]
            }

            //也可以同时输出到文件
            file {
                path => "/path/to/target/file"
            }
        }
        ```

- 指定conf做测试检查
    ```bash
    ./bin/logstash -f ./conf.d/first-pipeline.conf --config.test_and_exit
    ```

- 检查输出OK后，开启
    ```bash
    ./bin/logstash -f first-pipeline.conf --config.reload.automatic
    ```
    - 最后的参数是自动重载文件，后面修改conf就无须重启

- 简单查询es

    ```bash
    curl -XGET 'localhost:9200/logstash-2021.07.26-000001/_search?pretty&q=response=200'
    ```
    ```bash
    curl -XGET 'localhost:9200/logstash-2021.07.26-000001/_search?pretty&q=geoip.city_name=Buffalo'
    ```